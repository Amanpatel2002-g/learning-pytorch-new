{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "\n",
    "why random tensors\n",
    "\n",
    "\n",
    "Randome tesors are important becuase the way many neural networks learn is that they start with tensors with tensorf full of randome and then adjust those randome numbers to better represent the data\n",
    "\n",
    "`Start with randome numbers -> look at the data -> update random numbers -> look at the data -> update random numbers`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7574, 0.9797, 0.3164, 0.7813],\n",
       "        [0.6453, 0.2258, 0.6177, 0.1818],\n",
       "        [0.2223, 0.4695, 0.4524, 0.2173]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  crearte a randome tensors of size (3, 4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0607, 0.6300, 0.1407, 0.1161, 0.4734, 0.9925, 0.1049, 0.9640,\n",
       "          0.1628, 0.1008],\n",
       "         [0.1860, 0.6404, 0.7153, 0.7784, 0.8869, 0.3039, 0.3232, 0.9888,\n",
       "          0.5634, 0.2243],\n",
       "         [0.1045, 0.8055, 0.5829, 0.5375, 0.2511, 0.4130, 0.9561, 0.7795,\n",
       "          0.6478, 0.7356],\n",
       "         [0.1117, 0.5881, 0.9414, 0.7448, 0.2893, 0.3419, 0.8006, 0.9201,\n",
       "          0.8815, 0.6467],\n",
       "         [0.4784, 0.9494, 0.9976, 0.0324, 0.2724, 0.8218, 0.1415, 0.3002,\n",
       "          0.9019, 0.8924],\n",
       "         [0.1531, 0.7680, 0.9144, 0.8659, 0.2072, 0.9864, 0.2248, 0.4575,\n",
       "          0.0544, 0.4484],\n",
       "         [0.9023, 0.5826, 0.4607, 0.9935, 0.3751, 0.8919, 0.0775, 0.9052,\n",
       "          0.7168, 0.4213],\n",
       "         [0.9174, 0.1392, 0.7256, 0.2435, 0.2337, 0.9169, 0.6966, 0.0437,\n",
       "          0.6449, 0.6404],\n",
       "         [0.7867, 0.1920, 0.0131, 0.7785, 0.7677, 0.6909, 0.5598, 0.7240,\n",
       "          0.3157, 0.0763],\n",
       "         [0.6341, 0.6880, 0.0901, 0.9889, 0.2340, 0.7053, 0.2443, 0.3518,\n",
       "          0.3556, 0.7957]],\n",
       "\n",
       "        [[0.9193, 0.2336, 0.6035, 0.0891, 0.1057, 0.3418, 0.6245, 0.6373,\n",
       "          0.9851, 0.0155],\n",
       "         [0.5205, 0.8179, 0.8493, 0.3775, 0.8251, 0.2022, 0.7998, 0.5268,\n",
       "          0.7208, 0.7407],\n",
       "         [0.2093, 0.7903, 0.4091, 0.9127, 0.8691, 0.1487, 0.8261, 0.6446,\n",
       "          0.6756, 0.0645],\n",
       "         [0.1330, 0.0842, 0.0922, 0.3742, 0.7311, 0.4249, 0.0685, 0.5386,\n",
       "          0.8387, 0.2727],\n",
       "         [0.2699, 0.9641, 0.5679, 0.9239, 0.0419, 0.3767, 0.5743, 0.7584,\n",
       "          0.9631, 0.2804],\n",
       "         [0.7789, 0.9179, 0.8470, 0.3885, 0.8809, 0.4945, 0.7695, 0.2631,\n",
       "          0.0234, 0.1692],\n",
       "         [0.8183, 0.9328, 0.4463, 0.9857, 0.6519, 0.6494, 0.4130, 0.5890,\n",
       "          0.7821, 0.8087],\n",
       "         [0.2495, 0.9459, 0.1524, 0.1538, 0.8096, 0.8864, 0.1853, 0.2858,\n",
       "          0.7664, 0.0172],\n",
       "         [0.9058, 0.3234, 0.2891, 0.8589, 0.6856, 0.2048, 0.2812, 0.3652,\n",
       "          0.2362, 0.1281],\n",
       "         [0.7981, 0.7013, 0.4080, 0.6228, 0.0932, 0.3462, 0.9288, 0.1685,\n",
       "          0.9629, 0.1462]],\n",
       "\n",
       "        [[0.5860, 0.3426, 0.1633, 0.3230, 0.9015, 0.1765, 0.5357, 0.0720,\n",
       "          0.3377, 0.2359],\n",
       "         [0.5498, 0.3614, 0.9609, 0.5127, 0.8411, 0.7169, 0.3864, 0.8915,\n",
       "          0.0681, 0.2023],\n",
       "         [0.2896, 0.2327, 0.0085, 0.4723, 0.4764, 0.9753, 0.4350, 0.4989,\n",
       "          0.0497, 0.9121],\n",
       "         [0.5543, 0.3708, 0.8421, 0.8304, 0.7807, 0.0398, 0.1178, 0.4569,\n",
       "          0.0270, 0.8343],\n",
       "         [0.0780, 0.2807, 0.7860, 0.1549, 0.8622, 0.4913, 0.6089, 0.5612,\n",
       "          0.7745, 0.0114],\n",
       "         [0.0199, 0.8609, 0.2558, 0.6785, 0.5710, 0.8140, 0.3953, 0.4930,\n",
       "          0.0640, 0.9187],\n",
       "         [0.9410, 0.9783, 0.9857, 0.8489, 0.1383, 0.4653, 0.9958, 0.1998,\n",
       "          0.1430, 0.0299],\n",
       "         [0.9481, 0.2790, 0.7450, 0.7524, 0.9921, 0.2724, 0.8432, 0.4249,\n",
       "          0.1639, 0.8111],\n",
       "         [0.1564, 0.2531, 0.2005, 0.7802, 0.8598, 0.2861, 0.4759, 0.5766,\n",
       "          0.8230, 0.2589],\n",
       "         [0.0560, 0.8911, 0.4036, 0.0430, 0.1513, 0.6423, 0.5840, 0.6096,\n",
       "          0.8689, 0.1389]],\n",
       "\n",
       "        [[0.4999, 0.2849, 0.5293, 0.0851, 0.2003, 0.8026, 0.6093, 0.6321,\n",
       "          0.3244, 0.2099],\n",
       "         [0.6594, 0.9976, 0.2168, 0.9438, 0.9377, 0.0643, 0.1237, 0.9444,\n",
       "          0.9268, 0.3184],\n",
       "         [0.5545, 0.0680, 0.0493, 0.1796, 0.4901, 0.3607, 0.1548, 0.0154,\n",
       "          0.4058, 0.2142],\n",
       "         [0.0949, 0.8579, 0.0865, 0.7208, 0.9363, 0.5436, 0.4263, 0.4949,\n",
       "          0.9623, 0.6177],\n",
       "         [0.7762, 0.0691, 0.7599, 0.9936, 0.1466, 0.4844, 0.4736, 0.3673,\n",
       "          0.6652, 0.6142],\n",
       "         [0.5825, 0.7499, 0.2485, 0.6068, 0.1966, 0.8248, 0.3875, 0.9349,\n",
       "          0.7823, 0.4264],\n",
       "         [0.5470, 0.1009, 0.5969, 0.8019, 0.3561, 0.9214, 0.0220, 0.0033,\n",
       "          0.1424, 0.1997],\n",
       "         [0.8212, 0.4632, 0.1219, 0.3491, 0.3206, 0.2999, 0.7007, 0.1575,\n",
       "          0.1905, 0.9122],\n",
       "         [0.3929, 0.9110, 0.9688, 0.6439, 0.3402, 0.5698, 0.5073, 0.5798,\n",
       "          0.0124, 0.2310],\n",
       "         [0.9538, 0.1167, 0.0072, 0.1446, 0.5109, 0.8382, 0.1096, 0.5843,\n",
       "          0.8983, 0.1560]],\n",
       "\n",
       "        [[0.5033, 0.1446, 0.0903, 0.9052, 0.2124, 0.7092, 0.8138, 0.1652,\n",
       "          0.5593, 0.4498],\n",
       "         [0.5932, 0.8354, 0.1460, 0.7431, 0.7055, 0.1692, 0.8500, 0.2152,\n",
       "          0.8510, 0.1998],\n",
       "         [0.7289, 0.3495, 0.1170, 0.0234, 0.7417, 0.5789, 0.9383, 0.4588,\n",
       "          0.3922, 0.9755],\n",
       "         [0.2603, 0.7182, 0.2391, 0.0271, 0.6414, 0.1551, 0.9028, 0.8525,\n",
       "          0.3738, 0.5468],\n",
       "         [0.3742, 0.8785, 0.7915, 0.4546, 0.9012, 0.6049, 0.7324, 0.5161,\n",
       "          0.9255, 0.6020],\n",
       "         [0.6817, 0.7794, 0.0621, 0.8221, 0.1260, 0.8420, 0.6395, 0.5028,\n",
       "          0.5466, 0.2149],\n",
       "         [0.7235, 0.6125, 0.4010, 0.3495, 0.3488, 0.4670, 0.0716, 0.7065,\n",
       "          0.5602, 0.2517],\n",
       "         [0.8778, 0.3356, 0.3919, 0.2560, 0.4071, 0.3806, 0.2442, 0.9360,\n",
       "          0.0686, 0.1132],\n",
       "         [0.5668, 0.4686, 0.3799, 0.3869, 0.2631, 0.2883, 0.9401, 0.8446,\n",
       "          0.7972, 0.0013],\n",
       "         [0.1553, 0.5541, 0.5312, 0.1608, 0.6184, 0.3547, 0.4605, 0.9684,\n",
       "          0.0053, 0.1374]],\n",
       "\n",
       "        [[0.8749, 0.1657, 0.9459, 0.8291, 0.3688, 0.3748, 0.8576, 0.5337,\n",
       "          0.3949, 0.0968],\n",
       "         [0.0403, 0.2985, 0.8321, 0.5676, 0.5563, 0.3564, 0.8266, 0.6014,\n",
       "          0.3905, 0.7351],\n",
       "         [0.3815, 0.1097, 0.9203, 0.8821, 0.5303, 0.9672, 0.9992, 0.3459,\n",
       "          0.4969, 0.7643],\n",
       "         [0.7243, 0.8609, 0.2425, 0.3385, 0.2215, 0.3823, 0.1299, 0.3182,\n",
       "          0.8492, 0.2043],\n",
       "         [0.3453, 0.4464, 0.2656, 0.1155, 0.3372, 0.6910, 0.9981, 0.3807,\n",
       "          0.3838, 0.1117],\n",
       "         [0.0732, 0.9073, 0.4833, 0.5500, 0.6405, 0.9442, 0.5524, 0.8921,\n",
       "          0.3243, 0.2927],\n",
       "         [0.2775, 0.6717, 0.8476, 0.4129, 0.8649, 0.8003, 0.4009, 0.0992,\n",
       "          0.5275, 0.5227],\n",
       "         [0.6972, 0.3021, 0.3480, 0.2770, 0.9296, 0.8276, 0.4049, 0.2891,\n",
       "          0.7468, 0.1204],\n",
       "         [0.0419, 0.7361, 0.1594, 0.3367, 0.4680, 0.9654, 0.6205, 0.7350,\n",
       "          0.4941, 0.1035],\n",
       "         [0.8739, 0.2294, 0.8537, 0.5094, 0.1722, 0.6425, 0.4943, 0.0473,\n",
       "          0.2374, 0.5346]],\n",
       "\n",
       "        [[0.3226, 0.8973, 0.0149, 0.6672, 0.3810, 0.3501, 0.4218, 0.4826,\n",
       "          0.9023, 0.5262],\n",
       "         [0.7572, 0.1699, 0.3699, 0.8455, 0.5914, 0.4179, 0.2392, 0.3186,\n",
       "          0.3895, 0.4636],\n",
       "         [0.1055, 0.5162, 0.7657, 0.5091, 0.6695, 0.2339, 0.0270, 0.6127,\n",
       "          0.2347, 0.6841],\n",
       "         [0.3111, 0.1934, 0.7952, 0.2667, 0.6186, 0.9660, 0.3164, 0.6462,\n",
       "          0.8120, 0.3490],\n",
       "         [0.7263, 0.2092, 0.2603, 0.5332, 0.5262, 0.5307, 0.7997, 0.1637,\n",
       "          0.9566, 0.4660],\n",
       "         [0.2549, 0.6996, 0.1063, 0.8313, 0.4602, 0.3931, 0.9554, 0.0787,\n",
       "          0.7829, 0.6018],\n",
       "         [0.2188, 0.5835, 0.1310, 0.6507, 0.7389, 0.3214, 0.5668, 0.9871,\n",
       "          0.9491, 0.7986],\n",
       "         [0.5370, 0.1451, 0.6322, 0.3057, 0.3212, 0.8101, 0.8881, 0.3778,\n",
       "          0.3575, 0.1404],\n",
       "         [0.9558, 0.9675, 0.0041, 0.6511, 0.6877, 0.3438, 0.0421, 0.1380,\n",
       "          0.5751, 0.8015],\n",
       "         [0.1743, 0.5022, 0.9541, 0.3638, 0.4018, 0.6298, 0.9833, 0.7658,\n",
       "          0.6719, 0.7547]],\n",
       "\n",
       "        [[0.6023, 0.0336, 0.2390, 0.7709, 0.7770, 0.4327, 0.9720, 0.9690,\n",
       "          0.0096, 0.6429],\n",
       "         [0.5329, 0.0194, 0.6394, 0.0619, 0.9059, 0.1416, 0.9819, 0.2719,\n",
       "          0.8034, 0.6419],\n",
       "         [0.8554, 0.9969, 0.9348, 0.0171, 0.0527, 0.5483, 0.8739, 0.4660,\n",
       "          0.4695, 0.6113],\n",
       "         [0.1053, 0.8822, 0.9691, 0.5557, 0.3320, 0.7142, 0.0966, 0.8131,\n",
       "          0.0985, 0.1810],\n",
       "         [0.1806, 0.1407, 0.4146, 0.9357, 0.7672, 0.7317, 0.3401, 0.3566,\n",
       "          0.2931, 0.2523],\n",
       "         [0.9179, 0.0230, 0.4530, 0.1401, 0.0017, 0.1356, 0.5332, 0.6310,\n",
       "          0.7932, 0.4853],\n",
       "         [0.6816, 0.3154, 0.2076, 0.1147, 0.1241, 0.6347, 0.2322, 0.1379,\n",
       "          0.3987, 0.6134],\n",
       "         [0.2742, 0.4516, 0.5851, 0.4380, 0.5778, 0.2594, 0.3510, 0.4926,\n",
       "          0.2617, 0.9167],\n",
       "         [0.6289, 0.1841, 0.6847, 0.1882, 0.5606, 0.7910, 0.0854, 0.7672,\n",
       "          0.7037, 0.4483],\n",
       "         [0.9548, 0.8360, 0.8766, 0.0109, 0.0079, 0.3122, 0.9888, 0.6906,\n",
       "          0.1590, 0.8840]],\n",
       "\n",
       "        [[0.5570, 0.8780, 0.8651, 0.1045, 0.2909, 0.6275, 0.0582, 0.0503,\n",
       "          0.3720, 0.1492],\n",
       "         [0.2599, 0.8469, 0.3676, 0.9221, 0.7850, 0.4133, 0.8979, 0.9878,\n",
       "          0.1949, 0.3155],\n",
       "         [0.8994, 0.1393, 0.8155, 0.3188, 0.3097, 0.5797, 0.9508, 0.3138,\n",
       "          0.8190, 0.4517],\n",
       "         [0.5560, 0.5411, 0.4341, 0.1917, 0.7998, 0.2904, 0.6608, 0.7346,\n",
       "          0.1034, 0.8950],\n",
       "         [0.2519, 0.4560, 0.5794, 0.2407, 0.2809, 0.0750, 0.3367, 0.1124,\n",
       "          0.7174, 0.5248],\n",
       "         [0.2343, 0.1737, 0.6512, 0.6287, 0.3167, 0.5814, 0.8746, 0.6388,\n",
       "          0.6706, 0.9293],\n",
       "         [0.7505, 0.1896, 0.6489, 0.9205, 0.6957, 0.5870, 0.2093, 0.2461,\n",
       "          0.6844, 0.8468],\n",
       "         [0.6352, 0.3164, 0.6790, 0.2497, 0.1006, 0.3646, 0.3269, 0.4822,\n",
       "          0.1673, 0.6835],\n",
       "         [0.3494, 0.2199, 0.0210, 0.2875, 0.3342, 0.5743, 0.1792, 0.2670,\n",
       "          0.0221, 0.6210],\n",
       "         [0.5913, 0.6380, 0.5451, 0.1431, 0.6939, 0.6987, 0.5932, 0.8291,\n",
       "          0.5992, 0.2521]],\n",
       "\n",
       "        [[0.7937, 0.1206, 0.4396, 0.0527, 0.2298, 0.6462, 0.4834, 0.0751,\n",
       "          0.5247, 0.6446],\n",
       "         [0.9254, 0.2956, 0.9145, 0.3798, 0.9554, 0.7133, 0.2039, 0.1235,\n",
       "          0.6172, 0.3247],\n",
       "         [0.7091, 0.0133, 0.5707, 0.6056, 0.6003, 0.6193, 0.9786, 0.4745,\n",
       "          0.8226, 0.8742],\n",
       "         [0.9695, 0.5847, 0.7455, 0.5712, 0.4512, 0.3321, 0.7478, 0.6179,\n",
       "          0.2516, 0.0117],\n",
       "         [0.7113, 0.4416, 0.4602, 0.8059, 0.6927, 0.1216, 0.1308, 0.1415,\n",
       "          0.7589, 0.6392],\n",
       "         [0.3318, 0.8785, 0.2684, 0.5620, 0.8412, 0.4228, 0.6970, 0.7338,\n",
       "          0.2558, 0.1489],\n",
       "         [0.0457, 0.1820, 0.0113, 0.7714, 0.9600, 0.9768, 0.2623, 0.4972,\n",
       "          0.1931, 0.4920],\n",
       "         [0.1001, 0.1258, 0.9004, 0.4591, 0.3011, 0.3905, 0.5835, 0.1462,\n",
       "          0.9894, 0.9612],\n",
       "         [0.5380, 0.4769, 0.9750, 0.7528, 0.9251, 0.6860, 0.5127, 0.0776,\n",
       "          0.3727, 0.7903],\n",
       "         [0.7961, 0.6013, 0.9647, 0.9126, 0.9809, 0.9086, 0.3016, 0.0702,\n",
       "          0.3378, 0.7459]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(10, 10, 10)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10*10*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # height , widht and colour channle ( Red, Green, Blue)\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2326, 0.6987, 0.6026],\n",
       "         [0.3974, 0.7736, 0.6465],\n",
       "         [0.5919, 0.3600, 0.6925],\n",
       "         ...,\n",
       "         [0.8347, 0.7367, 0.3264],\n",
       "         [0.2161, 0.9376, 0.0369],\n",
       "         [0.6691, 0.3501, 0.5351]],\n",
       "\n",
       "        [[0.9743, 0.6460, 0.7316],\n",
       "         [0.5977, 0.9309, 0.8383],\n",
       "         [0.0087, 0.6713, 0.9202],\n",
       "         ...,\n",
       "         [0.1687, 0.4580, 0.9913],\n",
       "         [0.8372, 0.1001, 0.5035],\n",
       "         [0.1487, 0.8059, 0.2600]],\n",
       "\n",
       "        [[0.5165, 0.4838, 0.9687],\n",
       "         [0.8364, 0.2498, 0.5925],\n",
       "         [0.7384, 0.8951, 0.1666],\n",
       "         ...,\n",
       "         [0.7674, 0.4953, 0.6944],\n",
       "         [0.2256, 0.4157, 0.8932],\n",
       "         [0.2533, 0.7724, 0.6194]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4326, 0.8994, 0.1004],\n",
       "         [0.5934, 0.6252, 0.1058],\n",
       "         [0.8706, 0.5666, 0.0881],\n",
       "         ...,\n",
       "         [0.2059, 0.3604, 0.1170],\n",
       "         [0.6065, 0.7659, 0.7087],\n",
       "         [0.8469, 0.3640, 0.0774]],\n",
       "\n",
       "        [[0.9629, 0.6573, 0.8469],\n",
       "         [0.2444, 0.1351, 0.6629],\n",
       "         [0.5421, 0.7366, 0.7741],\n",
       "         ...,\n",
       "         [0.7738, 0.1411, 0.0720],\n",
       "         [0.6690, 0.5256, 0.2906],\n",
       "         [0.9517, 0.9403, 0.2736]],\n",
       "\n",
       "        [[0.8591, 0.4627, 0.6930],\n",
       "         [0.0209, 0.4555, 0.8773],\n",
       "         [0.1052, 0.1253, 0.3857],\n",
       "         ...,\n",
       "         [0.7104, 0.9358, 0.7171],\n",
       "         [0.3698, 0.9916, 0.9249],\n",
       "         [0.7666, 0.4757, 0.8139]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9810],\n",
       "         [0.8485],\n",
       "         [0.9820]],\n",
       "\n",
       "        [[0.7565],\n",
       "         [0.5517],\n",
       "         [0.1107]],\n",
       "\n",
       "        [[0.4788],\n",
       "         [0.6391],\n",
       "         [0.6472]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((3,3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4 ))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### creating a range of tensors\n",
    "\n",
    "one_to_ten = torch.arange(0, end=1000, step=77)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensos like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype=None,\n",
    " device=None,\n",
    "requires_grad=False)\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor =  torch.tensor([3, 6, 9], dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.long)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEtting information from tensors\n",
    "\n",
    "1. **Tensors not right datatype** - to do get datatype from a tensor, can use the `tensor.dtype`\n",
    "2. **Tensors not right shape** - tp get shape from a tensor, can use `tensor.shape`\n",
    "3. **Tensors not on the right device** - to get device from a tensor, can use tensor.device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3702, 0.1591, 0.7877, 0.4556],\n",
       "        [0.5346, 0.0415, 0.5917, 0.4421],\n",
       "        [0.1343, 0.1618, 0.0733, 0.5802]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3702, 0.1591, 0.7877, 0.4556],\n",
      "        [0.5346, 0.0415, 0.5917, 0.4421],\n",
      "        [0.1343, 0.1618, 0.0733, 0.5802]])\n",
      "Datatype of tensor: torch.float32\n",
      "Device Tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about somoe tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device Tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of tensor: {some_tensor.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors\n",
    "\n",
    "Tensors operations includem:\n",
    "* Addition\n",
    "* Substraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multiplication \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor+ 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mulitply by 10\n",
    "tensor* 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Matrix Multiplication \n",
    "\n",
    "Two main ways of peroforming Multiplication in neural networks and deep learning\n",
    "\n",
    "1. Element-wise Multiplication\n",
    "2. Matrix multiplication\n",
    "\n",
    "\n",
    "More information on multiplying metrics: https://www.mathsisfun.com/algebra/matrix-multiplying.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element wise mutliplication\n",
    "\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 23,  32],\n",
       "        [ 53,  74],\n",
       "        [ 83, 116]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorA = torch.tensor([[1, 2],\n",
    "                        [3, 4],\n",
    "                        [5, 6]])\n",
    "\n",
    "tensorB = torch.tensor([[7, 10],\n",
    "                        [8, 11]])\n",
    "\n",
    "torch.mm(tensorA, tensorB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 5],\n",
       "        [2, 4, 6]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorA.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshapping, stacking, squeezing and unsqueezzing tensors\n",
    "\n",
    "* Reshaping: - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of centerain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side\n",
    "* Squeeze - remove all `1` dimensions from a tensor\n",
    "* Unsqueeze - Return a view of input with dimensions permuted (swapped) in a certain way \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Let's creeate a tensor\n",
    "import torch\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimmenstion\n",
    "x_reshapped = x.reshape((1, 9))\n",
    "x_reshapped, x_reshapped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshpaed = x.reshape(3, 3)\n",
    "x_reshpaed, x_reshpaed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9]), tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the view\n",
    "\n",
    "z = x.view(1, 9)\n",
    "z.shape, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: changing the `z` would change the x as well bcs `z` and `x` both share the same memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sack tensors onthe top of each other\n",
    "x_stacked = torch.stack([x, x, x, x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshpaed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshaped = x_reshapped.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape:  torch.Size([9])\n",
      "New target: tensor([[5.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "New shape:  torch.Size([9, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() -  adds a single dimnestion to a target tensor at a specific dim (dimmenstion)\n",
    "print(f\"Previous target: {x_reshaped}\")\n",
    "print(f\"Previous shape:  {x_reshaped.shape}\")\n",
    "\n",
    "x_unsqeezed = torch.unsqueeze(x_reshaped, dim=1)\n",
    "\n",
    "print(f\"New target: {x_unsqeezed}\")\n",
    "print(f\"New shape:  {x_unsqeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)\n",
    "\n",
    "Indexing with pytorch is similar to indexing in numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on our new tensor\n",
    "x[0, :2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_squeezed = x.squeeze()\n",
    "x_squeezed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tensors & Numpy\n",
    "\n",
    "NumPy is a popular scientific Python numcerical computing library \n",
    "\n",
    "And because of this, Pytorch has functionality to interact with it.\n",
    "\n",
    "* Data in Numpy, want in Pytorch tensor -> `torch.form_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array).type(torch.float32) # when converting from numpy to pytorch, pytorch reflexcts numpy's deafult datatpe of float64 unless specified otherwise\n",
    "array, tensor\n",
    "\n",
    "## if we want to change the dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the tensor, what happens to 'numpy_tensor`\n",
    "# `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility (trying to take random out of random)\n",
    "\n",
    "In short how a neural network learns:\n",
    "\n",
    "`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again...`\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a **random\n",
    " seed**\n",
    "\n",
    "Essentially what the randome seed does is \"flavour\" the randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9852, 0.7546, 0.5623, 0.8118],\n",
      "        [0.7187, 0.5504, 0.5731, 0.4981],\n",
      "        [0.8844, 0.4717, 0.7599, 0.9545]])\n",
      "tensor([[0.8066, 0.1070, 0.1761, 0.3754],\n",
      "        [0.6020, 0.4405, 0.3643, 0.9056],\n",
      "        [0.6737, 0.5468, 0.8544, 0.8155]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# create two random tensors\n",
    "\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_B==random_tensor_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "# set the random seed\n",
    "RANDOM_SEED  =  42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tensors and Pytorch objects on the GPUs (and making faster computation)\n",
    "\n",
    "GPUs = faster computationl on numbers, thanks to CUDA  + NVIDIA hardware + Pytorch working behind the scenes to make everything hunky dory (good).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a GPU\n",
    "\n",
    "1. Easiest - Use Google Colab for a free \n",
    "2. Use your own GPU - takes a little bit of setup and requires the investment of purchasing a GPU, there's lots of options...., see this post for what optioms to get:\n",
    "https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/\n",
    "3. Use Cloud Computing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar  7 11:07:51 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050        Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   43C    P8              N/A /  35W |      6MiB /  3072MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     15639      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Putting tensors (and models ) on the GPU\n",
    "\n",
    "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on the GPU)\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU ( if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving tenors back to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fix the GPU tensor with Numpy issue, we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
